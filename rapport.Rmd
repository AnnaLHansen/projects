---
title: "Report - Machine Learning DTU"
output: html_document
author: Anna Hansen - Udviklings- og forenklingsstyrrelsen
---

```{r, echo = FALSE, message= FALSE}
library(dplyr)
library(knitr)
setwd("~/projects")
source("help_func_datainspec.R")
source("help_func_standardization.R")
```


# Part I

**Beskrivelse af data** \
Alle boligejere i Danmark betaler en skat, ejendomsværdiskat, som er baseret på værdien af deres ejendom. Dette vil sige hele ejendommen inkl. grunden som boligen ligger på. For at kunne gøre dette laver den danske stat offentlige ejendomsvurderinger som disse skatter bliver baseret på. 
Det er derfor vigtigt at disse vurderinger er retvisende og ikke mindst forklarbare, således at en borger kan forstå hvilke parametre der ligger til grund for ejendomsvurderingen. 
Til dette project har jeg valgt at arbejde med anonymiseret data fra mit arbejde i udviklings- og forenklingsstyrrelsen, hvor jeg til dagligt arbejder med netop dette. Datasættet består af ejendomssalg fra en 6 årig periode. Ud over selve huspriserne består data også af en lang række attributter som beskriver karakteristika ved selve boligen. Det kan f.eks. være tagmateriale, boligens opførelsesår, information om størrelsen af huset og grunden eller bbr koder som dækker over boligens anvendelse. 
Der ud over består data også af en lang række attributter som fortæller noget om hvor boligens beliggenhed. Det kan f.eks. være boligens koordinater eller information om afstanden til kyst og skov eller afstand til motorvej og jernbane. 
Data kommer fra en række forskellige registre og offentlige styrrelser som eks. BBR og Styrrelsen for Dataforsyning og Effektivisering.

Til dette projekt vil jeg overordnet set prøve at se hvor godt man kan forudsige ejendomsværdier ud fra salgspriserne fra en 6-årig periode. 

Jeg vil med Principal Component Analysis få et overblik over de data der er til rådighed og få et visuelt overblik over attributterne. 
Herefter vil jeg med en unsupervised learning forsøge at gruppere det data jeg har til at generer yderlige attributer som kan indgå i modellen. Jeg vil her specifikt prøve at se om det er muligt at gruppere salgene i forskellige boligtyper. Jeg vil i samme omgang også forsøge at frasorterer outliers i data med anomaly detection. 
Herefter vil jeg med regressions model forsøge at kaste lys over projektets overordnede problem ved at forsøge at forudsige huspriserne ud fra salgspriser. I tilfælde af at modellen ikke ikke kan komme med en god prædiktion af en given ejendom vil det være muligt at denne ejendom bliver manuelt værdiansat af en sagsbehandler. Jeg vil derfor til slut med en classifikation forsøge at estimerer om en ejendom skal ud til manuel sagsbehandling baseret på dens estimerede ejendomsværdi.


** Detaljeret beskrivelse af data** \

```{r, echo=FALSE}
train <- readRDS("~/1_A_Machine_learning_kursus_data/anonym_data_kursus.rds")
```

Det salgsdata som jeg har valgt at arbejde med dækker i udgangspunktet `r nrow(train)` observationer med `r ncol(train)` attributter. Inden jeg går i gang med at kigge på data har jeg valgt at lave en oprydning i data. Det har jeg gjort fordi mange af attributterne bliver i mit daglige arbejde brugt i forbindelse med imødekomme diverse forretningskrav. Desuden dækker observationerne mange forskellige typer af ejendomssalg. Det er en blanding af parcelhussalg, rækkehussalg, sommerhussalg, salg af ejerlejligheder mm. og ud fra et forretningsmæssigt perspektiv giver det ikke mening at træne en model på alle salg og ejendomstypen vil påvirke salgsprisen. F.eks. vil der på sommerhuse være restriktioner på hvor meget om året man må bo i sommerhuset og der kan være i sommerhusområder være andre regler for hvad man må bruge sin grund til end der er i et parcelhusområde. Jeg har derfor ligeledes valgt at reducerer antallet af observationer således at de kun dækker almindelige parcelhus. Dette er gjort ved kun at beholde alle de ejendomssalg, hvor ejendommen i BBR er registreret med enheds- og bygningsanvendelsen 120. 

```{r, echo=FALSE}
train <- readRDS("~/1_A_Machine_learning_kursus_data/train_klargjort_salg.rds")
```
Herefter er der `r nrow(train)` observationer tilbage og `r ncol(train)` attributter. 

Der er for en del af attributterne en stor andel af manglende værdier. Det er især i forhold til variable fra BBR, som beskriver forskellige karakteristika ved selve boligen. Her har jeg har valgt at fjerne alle de attributter som har mere end 95% manglende værdier.

```{r, echo = FALSE}
attribut_oversigt <- readRDS("~/1_A_Machine_learning_kursus_data/attribut_oversigt.rds")
attribut_oversigt <- attribut_oversigt[order(attribut_oversigt$pct_missing_values, decreasing = TRUE),]
knitr::kable(attribut_oversigt)
```

Som udgangspunkt vil jeg træne en model som skal være i stand til at kunne prædiktere værdien af et standard parcelhus. Data som der skal trænes på skal derfor også være salg af standard parcelhuse. 
Data er derfor blevet ensrettet på følgende måde: \

- enhed.antalvaerelser > 1 & enhed.antalvaerelser < 10
- bolig_areal < 500 & bolig_areal > 50
- bolig_alder > 0 & bolig_alder < 100
- bygning.antaletager > 0 & bygning.antaletager < 4
- enhed.antalbadevaerelser > 0 & enhed.antalbadevaerelser < 4
- enhed.antalvandskylledetoiletter > 0 & enhed.antalvandskylledetoiletter < 4
- fremskreven_pris_M2 < 30000 & fremskreven_pris_M2 > 0

Slutteligt er der blevet taget et valg om kun at udvælge de rå attributter som menes at være de vigtigste i forhold til at forudsige værdien af et standad parcelhus. 

```{r, echo=FALSE}
train <- readRDS("~/1_A_Machine_learning_kursus_data/train_behandlet.rds")
attribut <- undersoeger_attributter(train)

knitr::kable(attribut)
```

De to attributter der dækker over tagtypematriale og ydervægsmateriale er diskrete variable som fordel kan normaliseres med en one-out-of-k transformering. 

Afstand til kyst og afstand til motorvej er to variable som jeg har valgt at binariserer. Det har jeg da de to features forud for denne rapport er blevet imputeret. For afstand til kyst er afstanden op til 1500 meter målt. Alt herover er imputeret til 1501 meter. Ligeledes er gjort for afstand til motorvej. 
For at håndtere disse variable har jeg som sagt valgt at binariserer dem. For afstand til kyst har jeg ud fra et forretningsmæssigt synspunkt valgt at en ejendom ligger så tæt på kysten at det har en effekt i dens værdi hvis den ligger inden for 300 meter af kysten. Det samme er gjort for afstand til vej. Her er grænsen dog blot 100 meter. 

```{r, echo = FALSE}
train <- one_out_of_k(train)
train <- binarisere_afstande(train)
```


**Data visualisering  - heriblandt Principal Component Analysis (PCA)** \

De forskellige attributter indeholder ikke værdier på samme skala og jeg har derfor valgt at standardisere data. Selve standardiseringen betyder at data for hver attribut reskaleres således at det får et gennemsnit på 1 med en standardafvigelse på 1.

$(X-\mu)/sd$ 

Efter at have standardiseret data laves der en correlationsanalyse hvor resultaterne af visualiseres i et correlationsplot.

```{r, echo = FALSE, message=FALSE, warning=FALSE}
library(corrplot)
train <- standardize(train)
correlation <- cor(train)
print(colnames(correlation))
rownames(correlation) <- 1:23
colnames(correlation) <- 1:23
corrplot(correlation)
```

```{r}
attributeNames <- colnames(train[1:ncol(train)])
X <- train[, 1:ncol(train)]
N = dim(X)[1]
M = dim(X)[2]
```

Salgsdata består efter alle datatransformationerne af `r N` observationer (N) med `r M` features (M).
En af de stærkere correlerede variable i data er EV_NN_M2 og de fremskrevne handelspriser. EV_NN_M2 er en variabel som dækker over områdeprisen. Den dækker over et vægtet gennemsnit over de nærmeste 15 solgte naboers kvadratmeterpriser. Det giver altså rigtig god mening at der er en stor korrelation mellem de solgte naboers kvadratmeter priser og ejendommens egen kvadratmeterpris. 
Når de to variable plottes mod hinanden ser det således ud:

```{r, echo = FALSE}
## Laver simpelt plot af udvalgte variable:
plot(X[ ,"EV_NN_M2"], X[ , "fremskreven_pris_M2"])
```

Der er en stærk korrelation mellem naboernes kvadratmeterpriser og ejendommens egen kvadratmeterpris. Det er fordi at priserne for en given lokation i høj grad er med til at bestemme prisen for en ejendom. 
Udover områdeprisen er det boligens egen karakteristika som er med til at udgøre den samlede ejendomsværdi.

Som en del af PCA udregnes herefter Singular Value Decomposition (SVD). 

```{r, echo = FALSE}
# 1 er per kolonne, 2 er per row..
Y <- t(apply(X,1,'-', colMeans(X))) # subtract the column means form columns of X
# You can check the column means using: colMeans(Y)
# PCA by computing SVD of Y:
# Bliver der her standardiseret to gange???
s <- svd(Y)
diagS <- s$d # d contains a vector of the singular values of x (of the length min(n, p))

rho <- (diagS^2)/(sum(diagS^2))
#sum(pcvariance[1:3])
threshold = 0.9

xlimits <- c(1, M); 
plot(rho,
     type='o',
     main="Variance explained by principal componenets",
     xlab="Principal components", 
     ylab="Variance explained",
     xlim=xlimits,
     ylim=c(0,1),
     col='blue')
lines(cumsum(rho), type='o', col='orange')
lines(xlimits, c(threshold, threshold), lty='dashed')

legend("right", # Define position
       legend=c("Individual", "Cumulative", "Threshold"), # Set strings for legend
       col=c("orange", "blue", "black"), lty=c(1,1,2), # Match appereance of lines
       cex=1.5, bg='lightblue') # Setup how the box looks (cex controls size)
```

De foeste 16 principal components kan man forklare 90% af variationen i data. For at kommme over 95% skal man have de 18 foerste komponenter. Der er i alt 23 mulige komponenter.
Det som det umiddelbart synes at betyde er at der ikke kan reduceres mange attibutter væk uden at det betyder at man mister variation.
PCA analysen kan bruges til at visualiserer data, feature extraction og compression.
Principal component analyse kan bruges til at reducerer dementionerne i data.

```{r, echo = FALSE}
Z <- s$u%*%diag(s$d)
i <- 1
j <- 2
plot(Z[, i ], Z[, j])
```


# Part II



# Part III